{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torchvision\nimport torchvision.transforms as transforms\n\n# veriler dönüştürülmeden yüklenecek. Görüntü nesneleri şeklinde olacak.\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True)\n\nfirst_element = train_dataset[0]\nimage, label = first_element\nprint(\"Verinin değişimden önceki şekli\")\nprint(type(image), image)\n\n# İki dönüşümü uygulayacak tek bir dönüşüm oluşturun:\n# 1. ToTensor(): Her görüntüdeki her pikseli RGB değerleri için üç\n#                sayıdan oluşan bir tensöre dönüştürün.\n# 2. Normalize(): değerleri [0,1] aralığından [-0.5, 0.5] değerine kaydırır\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n# veriler yüklenir ve dönüşümler uygulanır\ntrain_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n                                        download=True, transform=transform)\n\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n                                       download=True, transform=transform)\n\nfirst_element = train_dataset[0]\nimage, label = first_element\nprint(type(image), image.shape)\nprint(\"Her görüntü 32x32 pikseldir ve her pikselin üç değeri vardır\")\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Bu işlev, tensör temsilini kullanarak görüntüyü gösterecektir.\ndef imshow(img):\n    img = img / 2 + 0.5  # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\nprint(\"İlk görüntü bir kurbağa görüntüsü!\")\nimshow(image)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:13:26.101839Z","iopub.execute_input":"2022-06-22T11:13:26.102685Z","iopub.status.idle":"2022-06-22T11:13:33.890845Z","shell.execute_reply.started":"2022-06-22T11:13:26.102649Z","shell.execute_reply":"2022-06-22T11:13:33.889823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n# her parti 4 görüntüden oluşacaktır\nbatch_size = 4\n\n# veri yükleyici örnekleri karıştıracak\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n                                          shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n                                         shuffle=False)\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(images.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:13:33.892618Z","iopub.execute_input":"2022-06-22T11:13:33.893345Z","iopub.status.idle":"2022-06-22T11:13:33.911425Z","shell.execute_reply.started":"2022-06-22T11:13:33.893305Z","shell.execute_reply":"2022-06-22T11:13:33.910238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\n\nconv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5)\n# input_channels = her giriş pikselindeki kanal sayısı\n# output_channels = her çıkış pikselindeki kanal sayısı\n# kernel_size = filtrenin genişliği ve yüksekliği\n\ndataiter = iter(train_loader)\nimages, labels = dataiter.next()\nprint(f\"katmandan önce, şekil: {images.shape}\")\noutput = conv1(images)\nprint(f\"katmandan sonra, şekil: {output.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:13:35.847719Z","iopub.execute_input":"2022-06-22T11:13:35.848107Z","iopub.status.idle":"2022-06-22T11:13:35.917518Z","shell.execute_reply.started":"2022-06-22T11:13:35.848073Z","shell.execute_reply":"2022-06-22T11:13:35.916676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pool = nn.MaxPool2d(kernel_size=2,stride=2)\n# kernel_size = filtrenin genişliği ve yüksekliği\n# stride = filtreleme işlemleri arasındaki mesafe\n\nprint(f\"katmandan önce, şekil: {output.shape}\")\noutput = pool(output)\nprint(f\"katmandan sonra, şekil: {output.shape}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:13:38.060673Z","iopub.execute_input":"2022-06-22T11:13:38.061057Z","iopub.status.idle":"2022-06-22T11:13:38.116374Z","shell.execute_reply.started":"2022-06-22T11:13:38.061025Z","shell.execute_reply":"2022-06-22T11:13:38.115387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        # ilk evrişim 5x5 boyutlarında bir filtre kullanır, piksel başına 3 giriş\n        # kanalı alır ve 6 çıkış kanalı üretir\n        self.conv1 = nn.Conv2d(3, 6, 5)\n        # 2x2 ızgaralı ve 2 adımlı max-pool kullanıyoruz. Havuz eğitilmediğinden,\n        # yalnızca bir örneğine ihtiyacımız var\n        self.pool1and2 = nn.MaxPool2d(2, 2)\n        # İkinci evrişim 5x5 boyutlarında bir filtre kullanır, ancak 6 giriş kanalı alır\n        # ve konum başına 16 çıkış kanalı üretir\n        self.conv2 = nn.Conv2d(6, 16, 5)\n        # Bu doğrusal katman, üzerine self.pool1and2 uygulandıktan sonra conv2'nin çıktısını\n        # alacaktır, bu da girdinin 16*5*5 değerine sahip olacağı anlamına gelir.\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        # Son doğrusal katman, tahmin edilecek 10 sınıf olduğundan 10 çıktı üretmelidir.\n        self.fc3 = nn.Linear(84, 10)\n    def forward(self, x):\n        # x -> [batch_size, 3, 32, 32]\n        output = self.conv1(x) # [batch_size, 6, 28, 28]\n        output = self.pool1and2(output) # [batch_size, 6, 14, 14]\n        output = F.relu(output) # [batch_size, 6, 14, 14]\n        output = self.conv2(output) # [batch_size, 16, 10, 10]\n        output = self.pool1and2(output) # [batch_size, 16, 5, 5]\n        output = F.relu(output) # [batch_size, 16, 5, 5]\n        # Doğrusal katmana beslemek için çıktıyı girdi başına tek bir satır haline getirmeliyiz.\n        output = output.reshape(-1, 16 * 5 * 5) # [batch_size, 16*5*5]\n        output = F.relu(self.fc1(output))\n        output = F.relu(self.fc2(output))\n        # Son katmandan sonra bir aktivasyon kullanmayacağız çünkü\n        # kayıp işlevi sigmoid aktivasyonunu otomatik olarak uygulayacaktır\n        output = self.fc3(output)\n        return output\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CNN().to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:13:40.440078Z","iopub.execute_input":"2022-06-22T11:13:40.440691Z","iopub.status.idle":"2022-06-22T11:13:43.593166Z","shell.execute_reply.started":"2022-06-22T11:13:40.440653Z","shell.execute_reply":"2022-06-22T11:13:43.591455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.001\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:13:47.016619Z","iopub.execute_input":"2022-06-22T11:13:47.016989Z","iopub.status.idle":"2022-06-22T11:13:47.021853Z","shell.execute_reply.started":"2022-06-22T11:13:47.016945Z","shell.execute_reply":"2022-06-22T11:13:47.020594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epochs = 6\n\n# Train_loader'daki parti sayısı\nn_total_steps = len(train_loader)\nfor epoch in range(num_epochs):\n\n    # Her toplu iş, bir görüntü tensörü ve bu görüntünün etiketlerini içeren\n    # bir tensörden oluşur.\n    for i, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n\n        # Giriş tensörü şu şekildedir: [batch_size, 3, 32, 32]\n        outputs = model(images)\n\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if (i+1) % 2000 == 0:\n            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:13:51.841551Z","iopub.execute_input":"2022-06-22T11:13:51.842166Z","iopub.status.idle":"2022-06-22T11:17:56.311397Z","shell.execute_reply.started":"2022-06-22T11:13:51.842126Z","shell.execute_reply":"2022-06-22T11:17:56.310582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = ('plane', 'car', 'bird', 'cat',\n           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\nwith torch.no_grad():\n    n_correct = 0\n    n_samples = 0\n    n_class_correct = [0 for i in range(10)]\n    n_class_samples = [0 for i in range(10)]\n    for images, labels in test_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n\n        _, predicted = torch.max(outputs, 1)\n        n_samples += labels.size(0)\n        n_correct += (predicted == labels).sum().item()\n\n        for i in range(batch_size):\n            label = labels[i]\n            pred = predicted[i]\n            if (label == pred):\n                n_class_correct[label] += 1\n            n_class_samples[label] += 1\n\n    acc = 100.0 * n_correct / n_samples\n    print(f'Ağın doğruluğu: {acc} %')\n\n    for i in range(10):\n        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n        print(f'{classes[i]} doğruluğu: {acc} %')","metadata":{"execution":{"iopub.status.busy":"2022-06-22T11:18:20.451069Z","iopub.execute_input":"2022-06-22T11:18:20.451523Z","iopub.status.idle":"2022-06-22T11:18:25.648414Z","shell.execute_reply.started":"2022-06-22T11:18:20.451484Z","shell.execute_reply":"2022-06-22T11:18:25.647491Z"},"trusted":true},"execution_count":null,"outputs":[]}]}